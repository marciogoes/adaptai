"""
üéì AdaptAI - Schemas de Prova
Schemas Pydantic para valida√ß√£o de dados
"""
from pydantic import BaseModel, Field, ConfigDict
from datetime import datetime
from typing import Optional, List, Dict, Any
from app.models.prova import (
    StatusProva, 
    StatusProvaAluno, 
    DificuldadeQuestao, 
    TipoQuestao
)


# ============= SCHEMAS DE CRIA√á√ÉO =============

class ProvaCreate(BaseModel):
    """Schema para criar uma nova prova"""
    titulo: str = Field(..., min_length=3, max_length=200, description="T√≠tulo da prova")
    descricao: Optional[str] = Field(None, description="Descri√ß√£o da prova")
    conteudo_prompt: str = Field(..., min_length=10, description="Prompt/conte√∫do para IA gerar quest√µes")
    materia: str = Field(..., min_length=2, max_length=100, description="Mat√©ria da prova")
    serie_nivel: Optional[str] = Field(None, max_length=50, description="S√©rie/n√≠vel escolar")
    quantidade_questoes: int = Field(20, ge=1, le=100, description="Quantidade de quest√µes")
    tipo_questao: TipoQuestao = Field(TipoQuestao.MULTIPLA_ESCOLHA, description="Tipo das quest√µes")
    dificuldade: DificuldadeQuestao = Field(DificuldadeQuestao.MEDIO, description="Dificuldade das quest√µes")
    tempo_limite_minutos: Optional[int] = Field(None, ge=1, description="Tempo limite em minutos")
    pontuacao_total: float = Field(10.0, ge=0, description="Pontua√ß√£o total da prova")
    nota_minima_aprovacao: float = Field(6.0, ge=0, le=10, description="Nota m√≠nima para aprova√ß√£o")


class QuestaoGeradaCreate(BaseModel):
    """Schema para criar uma quest√£o gerada"""
    numero: int = Field(..., ge=1, description="N√∫mero da quest√£o")
    enunciado: str = Field(..., min_length=10, description="Enunciado da quest√£o")
    tipo: TipoQuestao = Field(..., description="Tipo da quest√£o")
    dificuldade: Optional[DificuldadeQuestao] = Field(None, description="Dificuldade")
    opcoes: Optional[List[str]] = Field(None, description="Op√ß√µes de resposta")
    resposta_correta: str = Field(..., description="Resposta correta")
    criterios_avaliacao: Optional[List[str]] = Field(None, description="Crit√©rios de avalia√ß√£o")
    pontuacao: float = Field(0.5, ge=0, description="Pontos da quest√£o")
    explicacao: Optional[str] = Field(None, description="Explica√ß√£o da resposta")
    tags: Optional[List[str]] = Field(None, description="Tags/t√≥picos")


class ProvaAlunoCreate(BaseModel):
    """Schema para associar prova a um aluno"""
    prova_id: int = Field(..., description="ID da prova")
    aluno_id: int = Field(..., description="ID do aluno")


class RespostaAlunoCreate(BaseModel):
    """Schema para registrar resposta do aluno"""
    questao_id: int = Field(..., description="ID da quest√£o")
    resposta_aluno: str = Field(..., description="Resposta do aluno")
    tempo_resposta_segundos: Optional[int] = Field(None, ge=0, description="Tempo de resposta")


# ============= SCHEMAS DE RESPOSTA =============

class QuestaoGeradaResponse(BaseModel):
    """Schema de resposta de quest√£o gerada"""
    id: int
    prova_id: int
    numero: int
    enunciado: str
    tipo: TipoQuestao
    dificuldade: Optional[DificuldadeQuestao]
    opcoes: Optional[List[str]]
    resposta_correta: str
    criterios_avaliacao: Optional[List[str]]
    pontuacao: float
    explicacao: Optional[str]
    tags: Optional[List[str]]
    criado_em: datetime

    model_config = ConfigDict(from_attributes=True)


class QuestaoParaAluno(BaseModel):
    """Schema de quest√£o para o aluno (SEM resposta correta)"""
    id: int
    numero: int
    enunciado: str
    tipo: TipoQuestao
    opcoes: Optional[List[str]]
    pontuacao: float

    model_config = ConfigDict(from_attributes=True)


class ProvaResponse(BaseModel):
    """Schema de resposta de prova"""
    id: int
    titulo: str
    descricao: Optional[str]
    conteudo_prompt: str
    materia: str
    serie_nivel: Optional[str]
    quantidade_questoes: int
    tipo_questao: TipoQuestao
    dificuldade: DificuldadeQuestao
    tempo_limite_minutos: Optional[int]
    pontuacao_total: float
    nota_minima_aprovacao: float
    status: StatusProva
    criado_em: datetime
    atualizado_em: datetime
    criado_por_id: int
    questoes: List[QuestaoGeradaResponse] = []

    model_config = ConfigDict(from_attributes=True)


class ProvaParaAluno(BaseModel):
    """Schema de prova para o aluno fazer"""
    id: int
    titulo: str
    descricao: Optional[str]
    materia: str
    serie_nivel: Optional[str]
    tempo_limite_minutos: Optional[int]
    pontuacao_total: float
    questoes: List[QuestaoParaAluno] = []

    model_config = ConfigDict(from_attributes=True)


class RespostaAlunoResponse(BaseModel):
    """Schema de resposta do aluno"""
    id: int
    prova_aluno_id: int
    questao_id: int
    resposta_aluno: str
    esta_correta: Optional[bool]
    pontuacao_obtida: Optional[float]
    pontuacao_maxima: Optional[float]
    feedback: Optional[str]
    tempo_resposta_segundos: Optional[int]
    respondido_em: datetime

    model_config = ConfigDict(from_attributes=True)


class ProvaAlunoResponse(BaseModel):
    """Schema de resposta de prova do aluno"""
    id: int
    prova_id: int
    aluno_id: int
    status: StatusProvaAluno
    data_atribuicao: datetime
    data_inicio: Optional[datetime]
    data_conclusao: Optional[datetime]
    data_correcao: Optional[datetime]
    pontuacao_obtida: Optional[float]
    pontuacao_maxima: Optional[float]
    nota_final: Optional[float]
    aprovado: Optional[bool]
    tempo_gasto_minutos: Optional[int]
    analise_ia: Optional[Dict[str, Any]]
    feedback_ia: Optional[str]
    respostas: List[RespostaAlunoResponse] = []
    prova: Optional[ProvaResponse] = None

    model_config = ConfigDict(from_attributes=True)


# ============= SCHEMAS DE ATUALIZA√á√ÉO =============

class ProvaUpdate(BaseModel):
    """Schema para atualizar prova"""
    titulo: Optional[str] = Field(None, min_length=3, max_length=200)
    descricao: Optional[str] = None
    status: Optional[StatusProva] = None
    tempo_limite_minutos: Optional[int] = Field(None, ge=1)
    pontuacao_total: Optional[float] = Field(None, ge=0)
    nota_minima_aprovacao: Optional[float] = Field(None, ge=0, le=10)


class ProvaAlunoUpdate(BaseModel):
    """Schema para atualizar prova do aluno"""
    status: Optional[StatusProvaAluno] = None
    data_inicio: Optional[datetime] = None
    data_conclusao: Optional[datetime] = None


# ============= SCHEMAS ESPECIAIS =============

class GerarProvaRequest(BaseModel):
    """
    Schema para solicitar gera√ß√£o de prova pela IA
    
    NOVO: Aceita aluno_ids e adaptacoes para criar prova contextualizada
    """
    titulo: str = Field(..., min_length=3, description="T√≠tulo da prova")
    descricao: Optional[str] = None
    conteudo_prompt: str = Field(..., min_length=20, description="Descri√ß√£o do conte√∫do para gerar quest√µes")
    materia: str = Field(..., description="Mat√©ria")
    serie_nivel: Optional[str] = None
    quantidade_questoes: int = Field(20, ge=1, le=50, description="Quantidade de quest√µes")
    tipo_questao: TipoQuestao = Field(TipoQuestao.MULTIPLA_ESCOLHA)
    dificuldade: DificuldadeQuestao = Field(DificuldadeQuestao.MEDIO)
    tempo_limite_minutos: Optional[int] = None
    pontuacao_total: float = Field(10.0, ge=0)
    nota_minima_aprovacao: float = Field(6.0, ge=0, le=10)
    # NOVO: IDs dos alunos para associar automaticamente
    aluno_ids: Optional[List[int]] = Field(default=None, description="IDs dos alunos para associar √† prova")
    # NOVO: Adapta√ß√µes necess√°rias (TEA, TDAH, etc.)
    adaptacoes: Optional[List[str]] = Field(default=None, description="Diagn√≥sticos/adapta√ß√µes dos alunos")


class IniciarProvaRequest(BaseModel):
    """Schema para aluno iniciar prova"""
    prova_aluno_id: int = Field(..., description="ID da associa√ß√£o prova-aluno")


class FinalizarProvaRequest(BaseModel):
    """Schema para aluno finalizar prova"""
    prova_aluno_id: int = Field(..., description="ID da associa√ß√£o prova-aluno")
    respostas: List[RespostaAlunoCreate] = Field(..., description="Lista de respostas")


class CorrigirProvaResponse(BaseModel):
    """Schema de resposta da corre√ß√£o"""
    prova_aluno_id: int
    pontuacao_obtida: float
    pontuacao_maxima: float
    nota_final: float
    aprovado: bool
    acertos: int
    erros: int
    percentual_acerto: float
    analise_ia: Dict[str, Any]
    feedback_ia: str
    respostas_detalhadas: List[RespostaAlunoResponse]

    model_config = ConfigDict(from_attributes=True)


class ProvaListResponse(BaseModel):
    """Schema para listagem de provas"""
    id: int
    titulo: str
    materia: str
    quantidade_questoes: int
    status: StatusProva
    criado_em: datetime
    criado_por_id: int

    model_config = ConfigDict(from_attributes=True)


class ProvaAlunoListResponse(BaseModel):
    """Schema para listagem de provas do aluno"""
    id: int
    prova_id: int
    status: StatusProvaAluno
    data_atribuicao: datetime
    nota_final: Optional[float]
    aprovado: Optional[bool]
    prova: Optional[ProvaListResponse] = None

    model_config = ConfigDict(from_attributes=True)
