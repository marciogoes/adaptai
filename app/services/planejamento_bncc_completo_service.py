# ============================================
# SERVICE - Planejamento Curricular BNCC COMPLETO
# ============================================
# Vers√£o ROBUSTA com:
# - Persist√™ncia de progresso no banco
# - Keep-alive no MySQL
# - Retry autom√°tico em caso de falha

import json
import asyncio
import uuid
import gzip
import hashlib
import re
from typing import Optional, List, Dict, Any
from datetime import datetime, date, timedelta
from sqlalchemy.orm import Session
from sqlalchemy import func, text

from app.core.config import settings
from app.models.student import Student
from app.models.curriculo import CurriculoNacional, MapeamentoPrerequisitos
from app.models.pei import PEI, PEIObjetivo
from app.models.relatorio import Relatorio
from app.models.planejamento_job import PlanejamentoJob, PlanejamentoJobLog, JobStatus


# Cliente Anthropic (inicializa√ß√£o lazy)
_client = None
MODELO_IA = "claude-sonnet-4-20250514"

# Configura√ß√µes de retry e processamento
MAX_RETRIES = 3  # Tentativas por lote
RETRY_DELAY = 2  # Segundos entre tentativas
LOTE_SIZE = 12   # Habilidades por lote (reduzido para maior seguran√ßa)
KEEPALIVE_INTERVAL = 30  # Segundos entre pings no MySQL
MAX_JSON_SIZE_BYTES = 500_000  # 500KB - acima disso comprime


def get_anthropic_client():
    global _client
    if _client is None:
        try:
            from anthropic import Anthropic
            _client = Anthropic(api_key=settings.ANTHROPIC_API_KEY)
        except Exception as e:
            print(f"[AVISO] Erro ao inicializar Anthropic: {e}")
    return _client


class PlanejamentoBNNCCompletoService:
    """
    Servi√ßo para gerar planejamento curricular COMPLETO
    com prote√ß√µes contra interrup√ß√£o.
    """
    
    def __init__(self, db: Session):
        self.db = db
        self.client = get_anthropic_client()
    
    # ============================================
    # M√âTODOS DE KEEP-ALIVE E PERSIST√äNCIA
    # ============================================
    
    def _keep_alive(self):
        """Faz ping no MySQL para manter conex√£o ativa"""
        try:
            self.db.execute(text("SELECT 1"))
            self.db.commit()
        except Exception as e:
            print(f"[KEEPALIVE] Erro no ping: {e}")
    
    def _comprimir_se_necessario(self, dados: Dict) -> Dict:
        """
        Comprime dados JSON se ultrapassar limite de tamanho.
        Retorna dados originais ou comprimidos com metadados.
        """
        json_str = json.dumps(dados, ensure_ascii=False)
        tamanho = len(json_str.encode('utf-8'))
        
        if tamanho > MAX_JSON_SIZE_BYTES:
            comprimido = gzip.compress(json_str.encode('utf-8'))
            resultado = {
                "__compressed__": True,
                "__algorithm__": "gzip",
                "__original_size__": tamanho,
                "__compressed_size__": len(comprimido),
                "__data__": comprimido.hex(),
                "__checksum__": hashlib.md5(json_str.encode()).hexdigest()
            }
            reducao = 100 - (len(comprimido)/tamanho*100)
            print(f"[üì¶ COMPRESS] {tamanho:,} bytes ‚Üí {len(comprimido):,} bytes ({reducao:.1f}% redu√ß√£o)")
            return resultado
        
        return dados
    
    def _descomprimir_se_necessario(self, dados: Dict) -> Dict:
        """
        Descomprime dados se estiverem comprimidos.
        """
        if isinstance(dados, dict) and dados.get("__compressed__"):
            try:
                comprimido = bytes.fromhex(dados["__data__"])
                json_str = gzip.decompress(comprimido).decode('utf-8')
                
                # Verificar checksum
                if dados.get("__checksum__"):
                    checksum_atual = hashlib.md5(json_str.encode()).hexdigest()
                    if checksum_atual != dados["__checksum__"]:
                        raise ValueError("Checksum inv√°lido - dados corrompidos")
                
                return json.loads(json_str)
            except Exception as e:
                print(f"[‚ùå DECOMPRESS] Erro: {e}")
                raise
        
        return dados
    
    def _criar_job(
        self,
        task_id: str,
        student_id: int,
        user_id: int,
        ano_letivo: str,
        componentes: List[str]
    ) -> PlanejamentoJob:
        """Cria um novo job de planejamento no banco"""
        job = PlanejamentoJob(
            task_id=task_id,
            student_id=student_id,
            user_id=user_id,
            ano_letivo=ano_letivo,
            status=JobStatus.PENDING.value,
            progress=0,
            message="Job criado, aguardando in√≠cio",
            componentes_solicitados=componentes,
            componentes_processados=[],
            resultados_parciais={}
        )
        self.db.add(job)
        self.db.commit()
        self.db.refresh(job)
        return job
    
    def _atualizar_job(
        self,
        job: PlanejamentoJob,
        status: str = None,
        progress: int = None,
        message: str = None,
        componente_atual: str = None,
        lote_atual: int = None,
        ultimo_erro: str = None
    ):
        """Atualiza o estado do job no banco"""
        if status:
            job.status = status
        if progress is not None:
            job.progress = progress
        if message:
            job.message = message
        if componente_atual is not None:
            job.componente_atual = componente_atual
        if lote_atual is not None:
            job.lote_atual = lote_atual
        if ultimo_erro:
            job.ultimo_erro = ultimo_erro
        
        job.updated_at = datetime.utcnow()
        self.db.commit()
        self._keep_alive()  # Mant√©m conex√£o ativa
    
    def _salvar_resultado_parcial(
        self,
        job: PlanejamentoJob,
        componente: str,
        objetivos: List[Dict]
    ):
        """Salva resultado parcial de um componente (com compress√£o se necess√°rio)"""
        resultados = job.resultados_parciais or {}
        if isinstance(resultados, str):
            resultados = json.loads(resultados)
        
        # Descomprimir se estava comprimido
        resultados = self._descomprimir_se_necessario(resultados)
        
        resultados[componente] = {
            "total_habilidades": len(objetivos),
            "objetivos": objetivos,
            "processado_em": datetime.utcnow().isoformat()
        }
        
        # Comprimir se muito grande
        resultados_para_salvar = self._comprimir_se_necessario(resultados)
        job.resultados_parciais = json.dumps(resultados_para_salvar, ensure_ascii=False)
        
        # Atualizar lista de componentes processados
        processados = job.componentes_processados or []
        if componente not in processados:
            processados.append(componente)
        job.componentes_processados = processados
        
        self.db.commit()
        self._keep_alive()
    
    def _salvar_checkpoint_lote(
        self,
        job: PlanejamentoJob,
        componente: str,
        lote_numero: int,
        objetivos_lote: List[Dict],
        objetivos_acumulados: List[Dict]
    ):
        """
        Salva checkpoint GRANULAR ap√≥s cada lote processado.
        Permite retomar do lote espec√≠fico em caso de crash.
        """
        try:
            resultados = job.resultados_parciais or {}
            if isinstance(resultados, str):
                resultados = json.loads(resultados)
            
            # Descomprimir se estava comprimido
            resultados = self._descomprimir_se_necessario(resultados)
            
            # Salvar progresso do componente atual (parcial)
            if componente not in resultados:
                resultados[componente] = {
                    "total_habilidades": 0,
                    "objetivos": [],
                    "lotes_processados": [],
                    "em_andamento": True
                }
            
            # Atualizar objetivos acumulados
            resultados[componente]["objetivos"] = objetivos_acumulados
            resultados[componente]["ultimo_lote"] = lote_numero
            
            # Registrar lotes j√° processados
            lotes_processados = resultados[componente].get("lotes_processados", [])
            if lote_numero not in lotes_processados:
                lotes_processados.append(lote_numero)
            resultados[componente]["lotes_processados"] = lotes_processados
            
            # Comprimir se muito grande
            resultados_para_salvar = self._comprimir_se_necessario(resultados)
            job.resultados_parciais = json.dumps(resultados_para_salvar, ensure_ascii=False)
            
            # Atualizar heartbeat e lote atual
            job.lote_atual = lote_numero
            if hasattr(job, 'last_heartbeat'):
                job.last_heartbeat = datetime.utcnow()
            
            self.db.commit()
            self._keep_alive()
            
            print(f"[üíæ CHECKPOINT] {componente} lote {lote_numero}: {len(objetivos_acumulados)} objetivos salvos")
            
        except Exception as e:
            print(f"[‚ö†Ô∏è CHECKPOINT] Erro ao salvar lote {lote_numero}: {e}")
            # N√£o propagar erro - o lote foi processado, s√≥ o checkpoint falhou
    
    def _obter_lotes_ja_processados(self, job: PlanejamentoJob, componente: str) -> tuple[List[int], List[Dict]]:
        """
        Recupera lotes j√° processados para um componente.
        Retorna (lista_de_lotes_processados, objetivos_acumulados)
        """
        try:
            resultados = job.resultados_parciais or {}
            if isinstance(resultados, str):
                resultados = json.loads(resultados)
            
            # Descomprimir se estava comprimido
            resultados = self._descomprimir_se_necessario(resultados)
            
            if componente in resultados:
                dados_componente = resultados[componente]
                lotes = dados_componente.get("lotes_processados", [])
                objetivos = dados_componente.get("objetivos", [])
                
                if lotes:
                    print(f"[üîÑ RECOVERY] {componente}: recuperados lotes {lotes} com {len(objetivos)} objetivos")
                    return lotes, objetivos
            
            return [], []
            
        except Exception as e:
            print(f"[‚ö†Ô∏è RECOVERY] Erro ao recuperar lotes de {componente}: {e}")
            return [], []
    
    def _registrar_log(
        self,
        job: PlanejamentoJob,
        evento: str,
        componente: str = None,
        lote: int = None,
        mensagem: str = None,
        dados: Dict = None
    ):
        """Registra evento no log do job"""
        log = PlanejamentoJobLog(
            job_id=job.id,
            evento=evento,
            componente=componente,
            lote=lote,
            mensagem=mensagem,
            dados=dados
        )
        self.db.add(log)
        self.db.commit()
    
    def obter_job(self, task_id: str) -> Optional[PlanejamentoJob]:
        """Busca um job pelo task_id"""
        return self.db.query(PlanejamentoJob).filter(
            PlanejamentoJob.task_id == task_id
        ).first()
    
    def obter_job_para_retomar(self, student_id: int, ano_letivo: str) -> Optional[PlanejamentoJob]:
        """Busca um job incompleto que pode ser retomado"""
        return self.db.query(PlanejamentoJob).filter(
            PlanejamentoJob.student_id == student_id,
            PlanejamentoJob.ano_letivo == ano_letivo,
            PlanejamentoJob.status.in_([
                JobStatus.PROCESSING.value,
                JobStatus.PAUSED.value,
                JobStatus.FAILED.value
            ])
        ).order_by(PlanejamentoJob.created_at.desc()).first()
    
    def verificar_job_em_andamento(self, student_id: int, ano_letivo: str) -> Optional[PlanejamentoJob]:
        """
        Verifica se j√° existe um job em andamento para o aluno.
        Usa SELECT FOR UPDATE para evitar race condition.
        """
        from datetime import timedelta
        limite_travado = datetime.utcnow() - timedelta(minutes=10)
        
        try:
            # LOCK AT√îMICO: SELECT FOR UPDATE impede que outra transa√ß√£o
            # leia/modifique estes registros at√© o commit
            result = self.db.execute(text("""
                SELECT id, task_id, status, updated_at, last_heartbeat
                FROM planejamento_jobs
                WHERE student_id = :student_id 
                AND ano_letivo = :ano_letivo
                AND status = 'processing'
                FOR UPDATE NOWAIT
            """), {"student_id": student_id, "ano_letivo": ano_letivo})
            
            job_row = result.fetchone()
            
            if job_row:
                job_id, task_id, status, updated_at, last_heartbeat = job_row
                
                # Verificar se est√° travado (sem atualiza√ß√£o por 10+ minutos)
                check_time = last_heartbeat or updated_at
                if check_time and check_time < limite_travado:
                    # Job travado - marcar como failed
                    self.db.execute(text("""
                        UPDATE planejamento_jobs 
                        SET status = 'failed',
                            ultimo_erro = 'Job travado (sem atualiza√ß√£o por 10+ minutos)',
                            completed_at = NOW()
                        WHERE id = :job_id
                    """), {"job_id": job_id})
                    self.db.commit()
                    print(f"[üîì LOCK] Job {job_id} travado, liberado para nova execu√ß√£o")
                    return None  # Permite criar novo
                
                # Job ativo encontrado
                job = self.db.query(PlanejamentoJob).filter(
                    PlanejamentoJob.id == job_id
                ).first()
                return job
            
            # Nenhum job ativo
            return None
            
        except Exception as e:
            erro_str = str(e).lower()
            # Se outro processo j√° tem o lock (NOWAIT retorna erro)
            if "lock" in erro_str or "timeout" in erro_str or "nowait" in erro_str:
                print(f"[üîí LOCK] Outro processo j√° est√° verificando este aluno")
                # Retornar um job "fake" para bloquear cria√ß√£o
                fake_job = PlanejamentoJob()
                fake_job.id = -1
                fake_job.status = "processing"
                fake_job.message = "Outro processo est√° iniciando job para este aluno"
                return fake_job
            
            # Outro erro - logar e permitir continuar
            print(f"[‚ö†Ô∏è LOCK] Erro na verifica√ß√£o: {e}")
            self.db.rollback()
            return None
    
    def adquirir_lock_job(self, student_id: int, ano_letivo: str, task_id: str) -> bool:
        """
        Tenta adquirir lock exclusivo para criar job.
        Retorna True se conseguiu, False se j√° existe job ativo.
        """
        try:
            # Tentar inserir registro de lock (usar task_id como chave √∫nica)
            # Se j√° existir job ativo, a verifica√ß√£o anterior j√° bloqueou
            
            # Verificar novamente com lock (double-check locking)
            result = self.db.execute(text("""
                SELECT COUNT(*) FROM planejamento_jobs
                WHERE student_id = :student_id 
                AND ano_letivo = :ano_letivo
                AND status = 'processing'
                FOR UPDATE
            """), {"student_id": student_id, "ano_letivo": ano_letivo})
            
            count = result.scalar()
            
            if count > 0:
                self.db.rollback()
                print(f"[üîí LOCK] Job j√° existe ap√≥s double-check")
                return False
            
            # Lock adquirido com sucesso
            self.db.commit()
            print(f"[üîì LOCK] Lock adquirido para student_id={student_id}")
            return True
            
        except Exception as e:
            self.db.rollback()
            print(f"[‚ö†Ô∏è LOCK] Erro ao adquirir lock: {e}")
            return False
    
    def limpar_jobs_antigos(self, student_id: int, manter_ultimos: int = 5):
        """
        Remove jobs antigos para n√£o acumular lixo no banco.
        Mant√©m apenas os √∫ltimos N jobs.
        """
        jobs = self.db.query(PlanejamentoJob).filter(
            PlanejamentoJob.student_id == student_id
        ).order_by(PlanejamentoJob.created_at.desc()).all()
        
        if len(jobs) > manter_ultimos:
            for job in jobs[manter_ultimos:]:
                # S√≥ remove se n√£o for PROCESSING
                if job.status != JobStatus.PROCESSING.value:
                    self.db.delete(job)
            self.db.commit()
    
    # ============================================
    # M√âTODOS DE BUSCA DE DADOS
    # ============================================
    
    def listar_componentes_disponiveis(self, ano_escolar: str) -> List[Dict[str, Any]]:
        """Lista componentes dispon√≠veis para um ano escolar"""
        self._keep_alive()
        
        results = self.db.query(
            CurriculoNacional.componente,
            func.count(CurriculoNacional.id).label('total')
        ).filter(
            CurriculoNacional.ano_escolar == ano_escolar
        ).group_by(
            CurriculoNacional.componente
        ).all()
        
        return [{"componente": r[0], "total_habilidades": r[1]} for r in results]
    
    def buscar_todas_habilidades(
        self,
        ano_escolar: str,
        componente: Optional[str] = None
    ) -> List[CurriculoNacional]:
        """Busca todas as habilidades da BNCC"""
        self._keep_alive()
        
        query = self.db.query(CurriculoNacional).filter(
            CurriculoNacional.ano_escolar == ano_escolar
        )
        
        if componente:
            query = query.filter(CurriculoNacional.componente == componente)
        
        return query.order_by(
            CurriculoNacional.componente,
            CurriculoNacional.trimestre_sugerido,
            CurriculoNacional.codigo_bncc
        ).all()
    
    def obter_perfil_aluno(self, student_id: int) -> Dict[str, Any]:
        """Obt√©m perfil completo do aluno"""
        self._keep_alive()
        
        student = self.db.query(Student).filter(Student.id == student_id).first()
        if not student:
            return {}
        
        relatorios = self.db.query(Relatorio).filter(
            Relatorio.student_id == student_id
        ).order_by(Relatorio.created_at.desc()).all()
        
        diagnosticos = student.diagnosis or {}
        dados_relatorios = []
        adaptacoes_consolidadas = []
        pontos_fortes = []
        dificuldades = []
        
        for rel in relatorios:
            if rel.dados_extraidos:
                dados = rel.dados_extraidos
                dados_relatorios.append({
                    "tipo": rel.tipo,
                    "resumo": dados.get("resumo_clinico", ""),
                })
                
                if "adaptacoes_sugeridas" in dados:
                    for key, value in dados["adaptacoes_sugeridas"].items():
                        if value:
                            adaptacoes_consolidadas.append(value)
                
                if "pontos_fortes" in dados:
                    pontos_fortes.extend(dados["pontos_fortes"])
                if "dificuldades" in dados:
                    dificuldades.extend(dados["dificuldades"])
                
                if "condicoes_identificadas" in dados:
                    condicoes = dados["condicoes_identificadas"]
                    if condicoes.get("tea"):
                        diagnosticos["tea"] = {"nivel": condicoes.get("tea_nivel")}
                    if condicoes.get("tdah"):
                        diagnosticos["tdah"] = True
                    if condicoes.get("dislexia"):
                        diagnosticos["dislexia"] = True
        
        return {
            "id": student.id,
            "nome": student.name,
            "ano_escolar": student.grade_level,
            "turma": student.turma,
            "diagnosticos": diagnosticos,
            "notes": student.notes,
            "adaptacoes_recomendadas": list(set(adaptacoes_consolidadas))[:10],
            "pontos_fortes": list(set(pontos_fortes))[:5],
            "dificuldades": list(set(dificuldades))[:5]
        }
    
    def _criar_perfil_resumido(self, perfil: Dict) -> str:
        """Cria vers√£o resumida do perfil"""
        return f"""
ALUNO: {perfil.get('nome', 'N/A')} - {perfil.get('ano_escolar', 'N/A')}

DIAGN√ìSTICOS:
{json.dumps(perfil.get('diagnosticos', {}), ensure_ascii=False)}

ADAPTA√á√ïES RECOMENDADAS:
{chr(10).join(['- ' + a for a in perfil.get('adaptacoes_recomendadas', [])[:8]]) or '- Nenhuma espec√≠fica'}

PONTOS FORTES:
{chr(10).join(['- ' + p for p in perfil.get('pontos_fortes', [])[:5]]) or '- A identificar'}

DIFICULDADES:
{chr(10).join(['- ' + d for d in perfil.get('dificuldades', [])[:5]]) or '- A identificar'}
""".strip()
    
    # ============================================
    # PROCESSAMENTO COM RETRY
    # ============================================
    
    async def _processar_lote_com_retry(
        self,
        job: PlanejamentoJob,
        perfil_resumido: str,
        componente: str,
        habilidades: List[Dict],
        ano_letivo: str,
        lote_numero: int
    ) -> Dict[str, Any]:
        """
        Processa um lote de habilidades COM RETRY autom√°tico.
        Tenta at√© MAX_RETRIES vezes em caso de falha.
        Inclui tratamento espec√≠fico para rate limits (429).
        """
        ultimo_erro = None
        RATE_LIMIT_BASE_WAIT = 4  # Base para backoff em rate limit
        
        for tentativa in range(1, MAX_RETRIES + 1):
            try:
                self._keep_alive()  # Manter conex√£o ativa antes de cada tentativa
                
                # Atualizar heartbeat do job
                if hasattr(job, 'last_heartbeat'):
                    job.last_heartbeat = datetime.utcnow()
                    job.heartbeat_count = (job.heartbeat_count or 0) + 1
                    self.db.commit()
                
                self._registrar_log(
                    job, "lote_iniciado", componente, lote_numero,
                    f"Tentativa {tentativa}/{MAX_RETRIES}",
                    {"habilidades": len(habilidades)}
                )
                
                resultado = await self._processar_lote_habilidades(
                    perfil_resumido, componente, habilidades, ano_letivo, lote_numero
                )
                
                if resultado.get("objetivos"):
                    self._registrar_log(
                        job, "lote_sucesso", componente, lote_numero,
                        f"Gerados {len(resultado['objetivos'])} objetivos",
                        {"objetivos_gerados": len(resultado['objetivos'])}
                    )
                    return resultado
                else:
                    raise Exception("Nenhum objetivo gerado")
                    
            except Exception as e:
                ultimo_erro = str(e)
                erro_lower = ultimo_erro.lower()
                
                # Tratamento espec√≠fico para rate limit (429)
                is_rate_limit = "rate" in erro_lower or "429" in erro_lower or "too many" in erro_lower
                
                if is_rate_limit:
                    wait_time = RATE_LIMIT_BASE_WAIT ** tentativa  # 4s, 16s, 64s
                    print(f"[‚è≥ RATE LIMIT] Lote {lote_numero} de {componente} - "
                          f"Tentativa {tentativa}/{MAX_RETRIES}. Aguardando {wait_time}s...")
                    
                    self._registrar_log(
                        job, "rate_limit", componente, lote_numero,
                        f"Rate limit - aguardando {wait_time}s",
                        {"wait_seconds": wait_time, "tentativa": tentativa}
                    )
                    
                    await asyncio.sleep(wait_time)
                    self._keep_alive()
                    continue
                
                print(f"[RETRY] Lote {lote_numero} de {componente} - Tentativa {tentativa} falhou: {e}")
                
                self._registrar_log(
                    job, "lote_erro", componente, lote_numero,
                    f"Erro na tentativa {tentativa}: {ultimo_erro}",
                    {"erro": ultimo_erro}
                )
                
                if tentativa < MAX_RETRIES:
                    await asyncio.sleep(RETRY_DELAY * tentativa)  # Backoff progressivo
                    self._keep_alive()
        
        # Todas as tentativas falharam
        print(f"[ERRO] Lote {lote_numero} de {componente} falhou ap√≥s {MAX_RETRIES} tentativas")
        job.tentativas += 1
        self._atualizar_job(job, ultimo_erro=ultimo_erro)
        
        return {
            "componente": componente,
            "lote": lote_numero,
            "objetivos": [],
            "erro": f"Falhou ap√≥s {MAX_RETRIES} tentativas: {ultimo_erro}"
        }
    
    async def _processar_lote_habilidades(
        self,
        perfil_resumido: str,
        componente: str,
        habilidades: List[Dict],
        ano_letivo: str,
        lote_numero: int
    ) -> Dict[str, Any]:
        """Processa um lote de habilidades (sem retry) - com valida√ß√£o robusta de JSON"""
        
        habilidades_texto = "\n".join([
            f"- [{h['codigo']}] T{h.get('trimestre', '?')}: {h['descricao'][:180]}"
            for h in habilidades
        ])
        
        prompt = f"""Voc√™ √© um especialista em educa√ß√£o inclusiva.

Gere adapta√ß√µes para TODAS as habilidades listadas, considerando o perfil do aluno.

{perfil_resumido}

## COMPONENTE: {componente}
## ANO LETIVO: {ano_letivo}

## HABILIDADES PARA ADAPTAR:
{habilidades_texto}

## INSTRU√á√ïES:
Para CADA habilidade, gere uma adapta√ß√£o espec√≠fica considerando o diagn√≥stico do aluno.

## FORMATO DE RESPOSTA (JSON):
{{
    "objetivos": [
        {{
            "codigo_bncc": "EFXXXX",
            "area": "{componente.lower()}",
            "trimestre": 1,
            "titulo": "T√≠tulo adaptado",
            "descricao_original": "Descri√ß√£o da BNCC",
            "descricao_adaptada": "Como trabalhar com este aluno",
            "adaptacoes": ["Adapta√ß√£o 1", "Adapta√ß√£o 2"],
            "estrategias_ensino": ["Estrat√©gia 1"],
            "materiais_recursos": ["Material 1"],
            "criterios_avaliacao": ["Crit√©rio adaptado"],
            "nivel_suporte": "alto|medio|baixo",
            "prioridade": "essencial|importante|complementar"
        }}
    ]
}}

IMPORTANTE:
- Gere UM objetivo para CADA habilidade listada
- Mantenha o c√≥digo BNCC original
- Retorne APENAS o JSON v√°lido, sem texto adicional"""

        message = self.client.messages.create(
            model=MODELO_IA,
            max_tokens=6000,
            messages=[{"role": "user", "content": prompt}]
        )
        
        response_text = message.content[0].text.strip()
        
        # Usar valida√ß√£o robusta com fallback
        resultado = self._validar_e_extrair_json(response_text, habilidades)
        
        return {
            "componente": componente,
            "lote": lote_numero,
            "objetivos": resultado.get("objetivos", [])
        }
    
    # ============================================
    # PROCESSAMENTO PRINCIPAL
    # ============================================
    
    async def gerar_planejamento_completo(
        self,
        student_id: int,
        ano_letivo: str,
        componentes: List[str] = None,
        user_id: int = None,
        task_id: str = None,
        task_manager = None,
        retomar_job: bool = True
    ) -> Dict[str, Any]:
        """
        Gera planejamento COMPLETO para TODAS as habilidades.
        Com persist√™ncia, keep-alive, retry, lock anti-duplica√ß√£o e compress√£o.
        """
        
        def update_progress(progress: int, message: str):
            if task_manager and task_id:
                task_manager.update_task(task_id, progress=progress, message=message)
            print(f"[{progress}%] {message}")
        
        if not self.client:
            raise Exception("Servi√ßo de IA n√£o dispon√≠vel")
        
        # Gerar task_id se n√£o fornecido
        if not task_id:
            task_id = str(uuid.uuid4())
        
        # PROTE√á√ÉO: Verificar se j√° existe job em andamento (evita duplica√ß√£o)
        job_ativo = self.verificar_job_em_andamento(student_id, ano_letivo)
        if job_ativo:
            raise Exception(
                f"J√° existe job em processamento para este aluno (ID: {job_ativo.id}). "
                f"Aguarde a conclus√£o ou aguarde o timeout autom√°tico."
            )
        
        # Tentar retomar job existente
        job = None
        if retomar_job:
            job = self.obter_job_para_retomar(student_id, ano_letivo)
            if job:
                print(f"[INFO] Retomando job existente: {job.task_id}")
                self._registrar_log(job, "job_retomado", mensagem="Job retomado")
        
        update_progress(5, "Carregando perfil do aluno...")
        
        # Obter perfil
        perfil = self.obter_perfil_aluno(student_id)
        if not perfil:
            raise Exception("Aluno n√£o encontrado")
        
        ano_escolar = perfil["ano_escolar"]
        
        # Se n√£o tem componentes, buscar todos
        if not componentes:
            componentes_info = self.listar_componentes_disponiveis(ano_escolar)
            componentes = [c["componente"] for c in componentes_info]
        
        # Criar novo job se n√£o estiver retomando
        if not job:
            job = self._criar_job(
                task_id=task_id,
                student_id=student_id,
                user_id=user_id or 0,
                ano_letivo=ano_letivo,
                componentes=componentes
            )
            self._registrar_log(job, "job_criado", mensagem=f"Componentes: {', '.join(componentes)}")
        
        # Atualizar status
        job.started_at = datetime.utcnow()
        self._atualizar_job(job, status=JobStatus.PROCESSING.value, message="Processando...")
        
        update_progress(10, f"Processando {len(componentes)} componentes...")
        
        # Determinar componentes j√° processados (para retomada)
        componentes_processados = job.componentes_processados or []
        componentes_pendentes = [c for c in componentes if c not in componentes_processados]
        
        if componentes_processados:
            print(f"[INFO] Componentes j√° processados: {componentes_processados}")
            print(f"[INFO] Componentes pendentes: {componentes_pendentes}")
        
        # Carregar resultados parciais existentes (com descompress√£o se necess√°rio)
        resultados_parciais = job.resultados_parciais or {}
        if isinstance(resultados_parciais, str):
            resultados_parciais = json.loads(resultados_parciais)
        resultados_parciais = self._descomprimir_se_necessario(resultados_parciais)
        
        perfil_resumido = self._criar_perfil_resumido(perfil)
        
        # Processar cada componente pendente
        progresso_base = 10
        progresso_por_componente = 80 / len(componentes)
        
        for idx, componente in enumerate(componentes):
            # Calcular progresso considerando j√° processados
            idx_real = componentes.index(componente)
            progresso_atual = progresso_base + (idx_real * progresso_por_componente)
            
            # Pular se j√° processado
            if componente in componentes_processados:
                update_progress(int(progresso_atual + progresso_por_componente), 
                              f"{componente} j√° processado anteriormente")
                continue
            
            self._atualizar_job(job, 
                              progress=int(progresso_atual),
                              message=f"Processando {componente}...",
                              componente_atual=componente,
                              lote_atual=0)
            
            update_progress(int(progresso_atual), f"Processando {componente}...")
            
            # Buscar habilidades
            self._keep_alive()
            habilidades_db = self.buscar_todas_habilidades(ano_escolar, componente)
            
            if not habilidades_db:
                print(f"[AVISO] Nenhuma habilidade para {componente} no {ano_escolar}")
                continue
            
            habilidades = [
                {
                    "id": h.id,
                    "codigo": h.codigo_bncc,
                    "descricao": h.habilidade_descricao,
                    "objeto_conhecimento": h.objeto_conhecimento,
                    "trimestre": h.trimestre_sugerido,
                    "dificuldade": h.dificuldade
                }
                for h in habilidades_db
            ]
            
            self._registrar_log(
                job, "componente_iniciado", componente,
                mensagem=f"{len(habilidades)} habilidades encontradas"
            )
            
            # CHECKPOINT GRANULAR: Recuperar lotes j√° processados
            lotes_ja_processados, objetivos_recuperados = self._obter_lotes_ja_processados(job, componente)
            todos_objetivos = objetivos_recuperados.copy() if objetivos_recuperados else []
            
            # Processar em lotes
            total_lotes = (len(habilidades) + LOTE_SIZE - 1) // LOTE_SIZE
            
            for lote_idx in range(0, len(habilidades), LOTE_SIZE):
                lote_numero = lote_idx // LOTE_SIZE + 1
                
                # PULAR lotes j√° processados (recupera√ß√£o granular)
                if lote_numero in lotes_ja_processados:
                    print(f"[‚è≠Ô∏è SKIP] {componente} lote {lote_numero}/{total_lotes} j√° processado")
                    continue
                
                lote = habilidades[lote_idx:lote_idx + LOTE_SIZE]
                
                self._atualizar_job(job, lote_atual=lote_numero,
                                  message=f"{componente}: lote {lote_numero}/{total_lotes}")
                
                progresso_lote = progresso_atual + (lote_numero / total_lotes * progresso_por_componente * 0.8)
                update_progress(int(progresso_lote), 
                              f"{componente}: processando lote {lote_numero}/{total_lotes}")
                
                # Processar lote COM RETRY
                resultado = await self._processar_lote_com_retry(
                    job, perfil_resumido, componente, lote, ano_letivo, lote_numero
                )
                
                if resultado.get("objetivos"):
                    todos_objetivos.extend(resultado["objetivos"])
                    
                    # CHECKPOINT: Salvar ap√≥s cada lote processado com sucesso
                    self._salvar_checkpoint_lote(
                        job, componente, lote_numero,
                        resultado["objetivos"], todos_objetivos
                    )
                
                # Pequena pausa entre lotes
                await asyncio.sleep(0.5)
                self._keep_alive()
            
            # Salvar resultado do componente
            self._salvar_resultado_parcial(job, componente, todos_objetivos)
            resultados_parciais[componente] = {
                "total_habilidades": len(habilidades),
                "objetivos": todos_objetivos
            }
            
            self._registrar_log(
                job, "componente_concluido", componente,
                mensagem=f"{len(todos_objetivos)} objetivos gerados",
                dados={"objetivos_gerados": len(todos_objetivos)}
            )
            
            update_progress(int(progresso_atual + progresso_por_componente),
                          f"{componente} conclu√≠do: {len(todos_objetivos)} objetivos")
        
        # Montar resultado final
        update_progress(95, "Finalizando planejamento...")
        
        planejamento_completo = {
            "aluno": {
                "id": perfil["id"],
                "nome": perfil["nome"],
                "ano_escolar": ano_escolar
            },
            "ano_letivo": ano_letivo,
            "componentes": resultados_parciais,
            "resumo": {
                "total_habilidades": sum(c.get("total_habilidades", 0) for c in resultados_parciais.values()),
                "total_objetivos_gerados": sum(len(c.get("objetivos", [])) for c in resultados_parciais.values()),
                "por_componente": {
                    comp: {
                        "habilidades": dados.get("total_habilidades", 0),
                        "objetivos_gerados": len(dados.get("objetivos", []))
                    }
                    for comp, dados in resultados_parciais.items()
                }
            },
            "orientacoes_gerais": self._gerar_orientacoes_gerais(perfil)
        }
        
        # Atualizar job como conclu√≠do (com compress√£o se necess√°rio)
        resultado_para_salvar = self._comprimir_se_necessario(planejamento_completo)
        job.resultado_final = json.dumps(resultado_para_salvar, ensure_ascii=False)
        job.completed_at = datetime.utcnow()
        self._atualizar_job(job, 
                          status=JobStatus.COMPLETED.value,
                          progress=100,
                          message="Planejamento completo gerado com sucesso!")
        
        self._registrar_log(job, "job_concluido", 
                          mensagem=f"Total: {planejamento_completo['resumo']['total_objetivos_gerados']} objetivos")
        
        update_progress(100, "Planejamento completo gerado!")
        
        return {
            "success": True,
            "job_id": job.id,
            "task_id": task_id,
            "planejamento": planejamento_completo
        }
    
    def _gerar_orientacoes_gerais(self, perfil: Dict) -> Dict[str, Any]:
        """Gera orienta√ß√µes baseadas no perfil"""
        diagnosticos = perfil.get("diagnosticos", {})
        
        orientacoes = {
            "ambiente": [],
            "comunicacao": [],
            "avaliacao": [],
            "rotina": []
        }
        
        if diagnosticos.get("tea"):
            orientacoes["ambiente"].extend([
                "Manter ambiente organizado e previs√≠vel",
                "Usar apoios visuais (cronogramas, pictogramas)",
                "Reduzir est√≠mulos sensoriais quando necess√°rio"
            ])
            orientacoes["comunicacao"].extend([
                "Usar linguagem clara e direta",
                "Dar tempo para processamento",
                "Evitar express√µes figuradas"
            ])
            orientacoes["rotina"].extend([
                "Antecipar mudan√ßas na rotina",
                "Usar timer visual para transi√ß√µes"
            ])
        
        if diagnosticos.get("tdah"):
            orientacoes["ambiente"].extend([
                "Sentar pr√≥ximo ao professor",
                "Minimizar distra√ß√µes visuais",
                "Permitir pausas para movimento"
            ])
            orientacoes["avaliacao"].extend([
                "Dividir tarefas em etapas menores",
                "Dar instru√ß√µes uma de cada vez",
                "Usar refor√ßo positivo frequente"
            ])
        
        if diagnosticos.get("dislexia"):
            orientacoes["comunicacao"].extend([
                "Usar fonte maior e espa√ßamento adequado",
                "Permitir leitura em voz alta",
                "Dar tempo extra para leitura"
            ])
            orientacoes["avaliacao"].extend([
                "Permitir avalia√ß√£o oral quando poss√≠vel",
                "N√£o penalizar erros ortogr√°ficos",
                "Usar recursos de √°udio"
            ])
        
        for key in orientacoes:
            orientacoes[key] = list(set(orientacoes[key]))
        
        return orientacoes
    
    # ============================================
    # SALVAR COMO PEI
    # ============================================
    
    def salvar_planejamento_completo(
        self,
        student_id: int,
        planejamento: Dict[str, Any],
        user_id: int,
        ano_letivo: str,
        job_id: int = None
    ) -> PEI:
        """Salva o planejamento completo como PEI"""
        self._keep_alive()
        
        ano = int(ano_letivo)
        data_inicio = date(ano, 2, 1)
        data_fim = date(ano, 12, 15)
        
        pei = PEI(
            student_id=student_id,
            created_by=user_id,
            ano_letivo=ano_letivo,
            tipo_periodo="anual",
            data_inicio=data_inicio,
            data_fim=data_fim,
            data_proxima_revisao=data_inicio + timedelta(days=90),
            ia_sugestoes_originais=planejamento,
            status="rascunho"
        )
        
        self.db.add(pei)
        self.db.flush()
        
        # Criar objetivos
        total_objetivos = 0
        for componente, dados in planejamento.get("componentes", {}).items():
            for obj_data in dados.get("objetivos", []):
                codigo_bncc = obj_data.get("codigo_bncc")
                
                curriculo_id = None
                if codigo_bncc:
                    curriculo = self.db.query(CurriculoNacional).filter(
                        CurriculoNacional.codigo_bncc == codigo_bncc
                    ).first()
                    if curriculo:
                        curriculo_id = curriculo.id
                
                trimestre = obj_data.get("trimestre", 1)
                prazo = self._calcular_prazo_trimestre(ano, trimestre)
                
                objetivo = PEIObjetivo(
                    pei_id=pei.id,
                    area=obj_data.get("area", componente.lower()),
                    curriculo_nacional_id=curriculo_id,
                    codigo_bncc=codigo_bncc,
                    titulo=obj_data.get("titulo", ""),
                    descricao=obj_data.get("descricao_adaptada", obj_data.get("descricao", "")),
                    meta_especifica=obj_data.get("meta_especifica", ""),
                    criterio_medicao=obj_data.get("criterios_avaliacao", [""])[0] if obj_data.get("criterios_avaliacao") else "",
                    valor_alvo=80,
                    prazo=prazo,
                    trimestre=trimestre,
                    adaptacoes=obj_data.get("adaptacoes"),
                    estrategias=obj_data.get("estrategias_ensino"),
                    materiais_recursos=obj_data.get("materiais_recursos"),
                    criterios_avaliacao=obj_data.get("criterios_avaliacao"),
                    origem="ia_sugestao",
                    ia_sugestao_original=obj_data
                )
                
                self.db.add(objetivo)
                total_objetivos += 1
                
                # Commit a cada 50 objetivos para evitar timeout
                if total_objetivos % 50 == 0:
                    self.db.flush()
                    self._keep_alive()
        
        self.db.commit()
        self.db.refresh(pei)
        
        # Atualizar job se fornecido
        if job_id:
            job = self.db.query(PlanejamentoJob).filter(PlanejamentoJob.id == job_id).first()
            if job:
                job.pei_id = pei.id
                self.db.commit()
        
        return pei
    
    def _limpar_json(self, text: str) -> str:
        """Remove marcadores de c√≥digo do texto"""
        if text.startswith("```json"):
            text = text[7:]
        if text.startswith("```"):
            text = text[3:]
        if text.endswith("```"):
            text = text[:-3]
        return text.strip()
    
    def _validar_e_extrair_json(self, response_text: str, habilidades: List[Dict]) -> Dict[str, Any]:
        """
        Valida√ß√£o ROBUSTA de JSON retornado pela IA.
        Tenta m√∫ltiplas estrat√©gias para extrair dados v√°lidos.
        """
        
        # Estrat√©gia 1: Parse direto do JSON limpo
        try:
            texto_limpo = self._limpar_json(response_text)
            resultado = json.loads(texto_limpo)
            
            # Validar estrutura b√°sica
            if self._validar_estrutura_objetivos(resultado, habilidades):
                return resultado
            
            print(f"[‚ö†Ô∏è JSON] Estrutura inv√°lida, tentando recupera√ß√£o...")
        except json.JSONDecodeError as e:
            print(f"[‚ö†Ô∏è JSON] Parse falhou: {e}. Tentando recupera√ß√£o...")
        
        # Estrat√©gia 2: Encontrar JSON dentro do texto com regex
        try:
            # Procurar por {"objetivos": [...]} no texto
            json_match = re.search(r'\{\s*["\']objetivos["\']\s*:\s*\[.*\]\s*\}', response_text, re.DOTALL)
            if json_match:
                resultado = json.loads(json_match.group())
                if self._validar_estrutura_objetivos(resultado, habilidades):
                    print(f"[‚úÖ JSON] Recuperado via regex (padr√£o 1)")
                    return resultado
        except Exception as e:
            print(f"[‚ö†Ô∏è JSON] Regex padr√£o 1 falhou: {e}")
        
        # Estrat√©gia 3: Extrair array de objetivos diretamente
        try:
            # Procurar por array de objetivos
            array_match = re.search(r'\[\s*\{.*?"codigo_bncc".*?\}\s*\]', response_text, re.DOTALL)
            if array_match:
                objetivos = json.loads(array_match.group())
                resultado = {"objetivos": objetivos}
                if self._validar_estrutura_objetivos(resultado, habilidades):
                    print(f"[‚úÖ JSON] Recuperado via regex (array direto)")
                    return resultado
        except Exception as e:
            print(f"[‚ö†Ô∏è JSON] Regex array falhou: {e}")
        
        # Estrat√©gia 4: Consertar JSON com problemas comuns
        try:
            texto_consertado = self._consertar_json(response_text)
            resultado = json.loads(texto_consertado)
            if self._validar_estrutura_objetivos(resultado, habilidades):
                print(f"[‚úÖ JSON] Recuperado ap√≥s conserto")
                return resultado
        except Exception as e:
            print(f"[‚ö†Ô∏è JSON] Conserto falhou: {e}")
        
        # Estrat√©gia 5: Gerar objetivos m√≠nimos de fallback
        print(f"[üîÑ FALLBACK] Gerando objetivos m√≠nimos para {len(habilidades)} habilidades")
        return self._gerar_objetivos_fallback(habilidades)
    
    def _validar_estrutura_objetivos(self, resultado: Dict, habilidades: List[Dict]) -> bool:
        """
        Valida se o resultado tem estrutura correta e quantidade m√≠nima de objetivos.
        """
        if not isinstance(resultado, dict):
            return False
        
        objetivos = resultado.get("objetivos", [])
        if not isinstance(objetivos, list):
            return False
        
        # Deve ter pelo menos 50% dos objetivos esperados
        minimo_esperado = max(1, len(habilidades) // 2)
        if len(objetivos) < minimo_esperado:
            print(f"[‚ö†Ô∏è VALID] Poucos objetivos: {len(objetivos)}/{len(habilidades)} (m√≠nimo: {minimo_esperado})")
            return False
        
        # Validar estrutura de cada objetivo
        campos_obrigatorios = ["codigo_bncc"]
        for obj in objetivos:
            if not isinstance(obj, dict):
                return False
            for campo in campos_obrigatorios:
                if campo not in obj:
                    print(f"[‚ö†Ô∏è VALID] Campo '{campo}' ausente em objetivo")
                    return False
        
        return True
    
    def _consertar_json(self, texto: str) -> str:
        """
        Tenta consertar problemas comuns em JSON malformado.
        """
        # Remover texto antes/depois do JSON
        texto = self._limpar_json(texto)
        
        # Encontrar in√≠cio e fim do JSON
        inicio = texto.find('{')
        fim = texto.rfind('}')
        if inicio != -1 and fim != -1:
            texto = texto[inicio:fim+1]
        
        # Consertar v√≠rgulas extras
        texto = re.sub(r',\s*}', '}', texto)
        texto = re.sub(r',\s*]', ']', texto)
        
        # Consertar aspas simples para duplas
        # Cuidado: n√£o substituir aspas dentro de strings
        texto = re.sub(r"(?<![\w])'([^']*)'(?![\w])", r'"\1"', texto)
        
        # Remover coment√°rios
        texto = re.sub(r'//.*?\n', '\n', texto)
        texto = re.sub(r'/\*.*?\*/', '', texto, flags=re.DOTALL)
        
        return texto
    
    def _gerar_objetivos_fallback(self, habilidades: List[Dict]) -> Dict[str, Any]:
        """
        Gera objetivos m√≠nimos quando a IA falha completamente.
        Permite que o processamento continue sem perder as habilidades.
        """
        objetivos = []
        
        for h in habilidades:
            objetivo = {
                "codigo_bncc": h.get("codigo", "UNKNOWN"),
                "area": "geral",
                "trimestre": h.get("trimestre", 1),
                "titulo": f"Objetivo para {h.get('codigo', 'habilidade')}",
                "descricao_original": h.get("descricao", "")[:200],
                "descricao_adaptada": f"Trabalhar a habilidade {h.get('codigo', '')} com adapta√ß√µes individualizadas.",
                "adaptacoes": ["Adaptar conforme necessidade do aluno"],
                "estrategias_ensino": ["Usar recursos visuais e concretos"],
                "materiais_recursos": ["Material adaptado"],
                "criterios_avaliacao": ["Avalia√ß√£o processual"],
                "nivel_suporte": "medio",
                "prioridade": "importante",
                "_fallback": True  # Marca que foi gerado automaticamente
            }
            objetivos.append(objetivo)
        
        return {"objetivos": objetivos}
    
    def _calcular_prazo_trimestre(self, ano: int, trimestre: int) -> date:
        """Calcula data limite de um trimestre"""
        if trimestre == 1:
            return date(ano, 4, 30)
        elif trimestre == 2:
            return date(ano, 7, 15)
        elif trimestre == 3:
            return date(ano, 10, 15)
        else:
            return date(ano, 12, 15)
