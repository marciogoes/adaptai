# üõ°Ô∏è Sistema de Prote√ß√£o de Jobs - AdaptAI

## Resumo das Prote√ß√µes Implementadas

Este documento descreve as prote√ß√µes implementadas para garantir robustez no processamento de jobs de planejamento BNCC.

---

## 1. üîÑ Checkpoints Incrementais (Railway crash/OOM)

**Problema:** Railway pode matar o processo (deploy, OOM, crash) deixando dados parciais.

**Solu√ß√£o:**
- Salvamento incremental ap√≥s cada componente processado
- Compress√£o autom√°tica de dados grandes (>500KB)
- Recupera√ß√£o autom√°tica de jobs incompletos

**Arquivos:**
- `app/services/job_protection_service.py` - `CheckpointManager`
- `app/services/planejamento_bncc_completo_service.py` - `_salvar_resultado_parcial()`

**Como funciona:**
```python
# A cada componente processado:
await salvar_checkpoint(job_id, "componente_X", dados_parciais)

# Na pr√≥xima execu√ß√£o, verifica se h√° checkpoint:
job = obter_job_para_retomar(student_id, ano_letivo)
if job:
    # Continua de onde parou
```

---

## 2. üîí Lock Anti-Duplica√ß√£o (Jobs simult√¢neos)

**Problema:** 2 jobs podem iniciar para o mesmo aluno, duplicando dados.

**Solu√ß√£o:**
- Verifica√ß√£o de job ativo antes de criar novo
- Lock com timeout autom√°tico (10 minutos)
- Libera√ß√£o autom√°tica de locks "travados"

**Arquivos:**
- `app/services/job_protection_service.py` - `JobLockManager`
- `app/services/planejamento_bncc_completo_service.py` - `verificar_job_em_andamento()`

**Como funciona:**
```python
# Antes de criar novo job:
job_ativo = verificar_job_em_andamento(student_id, ano_letivo)
if job_ativo:
    raise Exception("J√° existe job em processamento")
```

---

## 3. üíì Heartbeat + Cleanup (Jobs travados)

**Problema:** Job pode ficar "preso" em PROCESSING se cair sem atualizar status.

**Solu√ß√£o:**
- Heartbeat atualizado a cada lote processado
- Cleanup autom√°tico no startup da aplica√ß√£o
- Jobs sem heartbeat h√° 5+ minutos s√£o marcados como FAILED

**Arquivos:**
- `app/models/planejamento_job.py` - Colunas `last_heartbeat`, `heartbeat_count`
- `app/main.py` - Cleanup no `startup_event()`
- `app/services/job_protection_service.py` - `HeartbeatManager`, `cleanup_stuck_jobs()`

**Como funciona:**
```python
# Durante processamento de cada lote:
job.last_heartbeat = datetime.utcnow()
job.heartbeat_count += 1

# No startup da aplica√ß√£o:
UPDATE planejamento_jobs 
SET status = 'failed'
WHERE status = 'processing'
AND last_heartbeat < NOW() - INTERVAL 5 MINUTE
```

---

## 4. ‚è≥ Retry Inteligente para Rate Limits (429)

**Problema:** Anthropic pode retornar rate limit (429) sem retry adequado.

**Solu√ß√£o:**
- Detec√ß√£o espec√≠fica de erro 429
- Backoff exponencial (4s, 16s, 64s)
- Logging detalhado de rate limits

**Arquivos:**
- `app/services/planejamento_bncc_completo_service.py` - `_processar_lote_com_retry()`
- `app/services/job_protection_service.py` - `retry_com_backoff()`

**Como funciona:**
```python
# Detec√ß√£o de rate limit:
if "rate" in erro or "429" in erro:
    wait_time = 4 ** tentativa  # 4s, 16s, 64s
    await asyncio.sleep(wait_time)
    continue  # Tenta novamente
```

---

## 5. üì¶ Compress√£o de Dados Grandes (JSON >500KB)

**Problema:** JSON muito grande pode causar problemas no banco com 500+ objetivos.

**Solu√ß√£o:**
- Compress√£o GZIP autom√°tica para dados >500KB
- Checksum MD5 para verificar integridade
- Descompress√£o transparente ao ler

**Arquivos:**
- `app/services/planejamento_bncc_completo_service.py` - `_comprimir_se_necessario()`, `_descomprimir_se_necessario()`
- `app/services/job_protection_service.py` - `DataCompressor`

**Como funciona:**
```python
# Ao salvar:
if len(json_str) > 500_000:
    comprimido = gzip.compress(json_str)
    dados = {"__compressed__": True, "__data__": comprimido.hex()}

# Ao ler:
if dados.get("__compressed__"):
    json_str = gzip.decompress(bytes.fromhex(dados["__data__"]))
```

---

## Colunas Adicionadas ao Banco

Execute a migration para adicionar as novas colunas:

```bash
python -m app.scripts.migrate_job_protection
```

**Colunas:**
- `last_heartbeat` - √öltima vez que o job sinalizou que est√° vivo
- `heartbeat_count` - Contador de heartbeats
- `lock_token` - Token √∫nico para controle de concorr√™ncia
- `lock_expires_at` - Expira√ß√£o do lock

---

## Fluxo Completo de Prote√ß√£o

```
1. Usu√°rio inicia planejamento
   ‚Üì
2. Verifica se j√° existe job ativo (LOCK)
   ‚Üì
3. Cria job com status PENDING
   ‚Üì
4. Inicia processamento (status = PROCESSING)
   ‚Üì
5. Para cada componente:
   - Atualiza heartbeat
   - Processa lotes com retry
   - Salva checkpoint parcial (comprimido se grande)
   ‚Üì
6. Finaliza job (status = COMPLETED)
   ‚Üì
7. Se crash durante 5: 
   - Startup detecta job travado
   - Marca como FAILED
   - Pr√≥xima execu√ß√£o retoma do checkpoint
```

---

## Logs de Prote√ß√£o

O sistema gera logs detalhados para cada prote√ß√£o:

```
[üíì HEARTBEAT] Job 123
[‚è≥ RATE LIMIT] Lote 2 de Matem√°tica - Aguardando 16s...
[üì¶ COMPRESS] 750,000 bytes ‚Üí 125,000 bytes (83.3% redu√ß√£o)
[üîÑ RECOVERY] Encontrado job recuper√°vel: 123
[üßπ CLEANUP] 3 jobs travados marcados como FAILED
```

---

## Tabela de Riscos vs Prote√ß√µes

| Risco | N√≠vel | Prote√ß√£o | Status |
|-------|-------|----------|--------|
| Railway crash/OOM | M√âDIO | Checkpoints | ‚úÖ |
| Jobs duplicados | M√âDIO | Lock | ‚úÖ |
| Job travado | M√âDIO | Heartbeat + Cleanup | ‚úÖ |
| Rate limit 429 | BAIXO | Retry inteligente | ‚úÖ |
| JSON muito grande | BAIXO | Compress√£o GZIP | ‚úÖ |

---

## Arquivos Modificados

1. `app/models/planejamento_job.py` - Novas colunas
2. `app/services/job_protection_service.py` - **NOVO** - Servi√ßo completo de prote√ß√£o
3. `app/services/planejamento_bncc_completo_service.py` - Integra√ß√£o das prote√ß√µes
4. `app/main.py` - Cleanup no startup
5. `app/scripts/migrate_job_protection.py` - **NOVO** - Migration para novas colunas
